{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path as path\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms as torch_transform\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "DRESS_FOLDER = \"../data/json/\"\n",
    "\n",
    "ID_NAME = \"retrieval_dresses.json\"\n",
    "TEST_NAME = \"test_pairs_dresses.json\"\n",
    "TRAIN_NAME = \"train_pairs_dresses.json\"\n",
    "PHOTO_FILE = \"../data/photos/photos_dress.txt\"\n",
    "SEED = 17\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1 upload dataset metadata and photos info</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'street2shop'...\n",
      "remote: Counting objects: 9, done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "Unpacking objects: 100% (9/9), done.\n",
      "remote: Total 9 (delta 1), reused 9 (delta 1), pack-reused 0\u001b[K\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0^C\n",
      "mv: rename street2shop/meta to data/meta: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pumpikano/street2shop\n",
    "!mkdir street2shop/images\n",
    "!bash street2shop/get_street2shop.sh\n",
    "!mkdir data\n",
    "!mv street2shop/meta data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â <h1>step 2 extract street photos only</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(file_name):\n",
    "    with open(file_name) as f:\n",
    "        obj = json.loads(f.readline())\n",
    "    return obj\n",
    "\n",
    "\n",
    "def get_photo_ids(obj, retr_dict):\n",
    "    photos = set()\n",
    "    for item in obj:\n",
    "        photos.add(item[\"photo\"])\n",
    "        product_photos = retr_dict[item[\"product\"]]\n",
    "        photos.update(product_photos)\n",
    "    return photos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ != \"__main__\":\n",
    "    id_to_photo_dirty = read_json(DRESS_FOLDER+ID_NAME)\n",
    "    id_to_photo_clean = {}\n",
    "    for item in id_to_photo_dirty:\n",
    "        if item[\"product\"] in id_to_photo_clean:\n",
    "            id_to_photo_clean[item[\"product\"]].append(item[\"photo\"])\n",
    "        else:\n",
    "            id_to_photo_clean[item[\"product\"]] = [item[\"photo\"]]\n",
    "    test_dress = read_json(DRESS_FOLDER + TEST_NAME)\n",
    "    train_dress = read_json(DRESS_FOLDER + TRAIN_NAME)\n",
    "    test_set = get_photo_ids(test_dress, id_to_photo_clean)\n",
    "    train_set = get_photo_ids(train_dress, id_to_photo_clean)\n",
    "    result_set = test_set|train_set\n",
    "\n",
    "    with open(PHOTO_FILE, \"w\") as new_ph_file:\n",
    "        with open(\"../data/photos/photos.txt\") as ph_file:\n",
    "            for line in ph_file:\n",
    "                id = int(line.split(\",\")[0])\n",
    "                if id in result_set:\n",
    "                    new_ph_file.write(line)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "download photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-29ab3a227978>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-29ab3a227978>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python download.py --urls data/photos/photos_dress.txt\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python download.py --urls data/photos/photos_dress.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get all available images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "\n",
    "PHOTO_FOLDER = \"../data/images\"\n",
    "\n",
    "ALL_IMAGES  = [int(name.split(\".\")[0]) for name in os.listdir(PHOTO_FOLDER) if path.isfile(PHOTO_FOLDER+\"/\"+name)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHOTO_FOLDER = \"../data/images\"\n",
    "META_FOLDER = \"../data/meta\"\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from skimage import io, transform\n",
    "\n",
    "IMG_SIZE =299\n",
    "\n",
    "def default_image_loader(path, crop=None,size=None):\n",
    "    if size is None:\n",
    "        size = (IMG_SIZE, IMG_SIZE)\n",
    "    image=Image.open(path).convert('RGB')\n",
    "    if crop is not None:\n",
    "        image = image.crop(crop)\n",
    "    image=image.resize(size)\n",
    "    return image\n",
    "\n",
    "def get_negative(positive, items):\n",
    "    while True:\n",
    "        rand_item = random.choice(items)\n",
    "        if positive != rand_item:\n",
    "            return rand_item\n",
    "    \n",
    "\n",
    "def get_image(photo_id, folder=PHOTO_FOLDER, crop=None,transform=None):\n",
    "    photo_name = str(photo_id)\n",
    "    zeros = \"0\"*(9- len(photo_name))\n",
    "    extension = \".jpeg\", \".png\", \".gif\"\n",
    "    full_photo_name = None\n",
    "    for ext in extension:\n",
    "        full_photo_name = folder+\"/\"+zeros+photo_name+ext\n",
    "        if path.isfile(full_photo_name):\n",
    "            break\n",
    "    else:\n",
    "        raise Exception(\"No Image found\")\n",
    "    image = default_image_loader(full_photo_name, crop=crop)\n",
    "    if transform is None:\n",
    "        return image\n",
    "    else:\n",
    "        return transform(image)\n",
    "\n",
    "class DressDataset(Dataset):\n",
    "    \"\"\"street2shop dress dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, triplets_file_name, photos_folder_name=PHOTO_FOLDER, \n",
    "                 retrieval_file_name=DRESS_FOLDER+ID_NAME, transform = None):\n",
    "        self.triplets = read_json(triplets_file_name)\n",
    "        self.retrieval = read_json(retrieval_file_name)\n",
    "        self.retrieval ={it[\"product\"]:it[\"photo\"] for it in self.retrieval}\n",
    "        all_photos = [item[\"photo\"] for item in self.triplets]\n",
    "        for item in self.triplets:\n",
    "            positive_photo = self.retrieval[item[\"product\"]]\n",
    "            anchor_photo = item[\"photo\"]\n",
    "            if positive_photo not in ALL_IMAGES or anchor_photo not in ALL_IMAGES:\n",
    "                continue\n",
    "            item[\"positive\"] = positive_photo\n",
    "            item[\"anchor\"] = anchor_photo\n",
    "            del item[\"product\"]\n",
    "            del item[\"photo\"]\n",
    "            negative = get_negative(item[\"positive\"], ALL_IMAGES)\n",
    "            item[\"negative\"] = negative\n",
    "        \n",
    "        for item in self.triplets[:]:\n",
    "            if \"positive\" not in item:\n",
    "                self.triplets.remove(item)\n",
    "            \n",
    "        self.photos_folder = photos_folder_name\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = {}\n",
    "        triplet = self.triplets[index]\n",
    "        sample[\"positive\"] = get_image(triplet[\"positive\"], transform = self.transform)\n",
    "        sample[\"negative\"] = get_image(triplet[\"negative\"], transform = self.transform)\n",
    "        bbox = triplet[\"bbox\"]\n",
    "        anchor = get_image(triplet[\"anchor\"], crop=(bbox[\"left\"],bbox[\"top\"],bbox[\"left\"]+bbox[\"width\"],bbox[\"top\"]+bbox[\"height\"]),\n",
    "                          transform=self.transform)\n",
    "        sample[\"anchor\"] = anchor\n",
    "        return (sample[\"positive\"], sample[\"anchor\"], sample[\"negative\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DressDataset(triplets_file_name=DRESS_FOLDER+TRAIN_NAME,\n",
    "                     transform=torch_transform.Compose([\n",
    "                                               torch_transform.ToTensor()\n",
    "                                           ]))\n",
    "test = DressDataset(triplets_file_name=DRESS_FOLDER+TRAIN_NAME,\n",
    "                   transform=torch_transform.Compose([\n",
    "                                               torch_transform.ToTensor()\n",
    "                                           ]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load dataset into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train,batch_size=BATCH_SIZE, shuffle=True,**kwargs)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test,batch_size=BATCH_SIZE, shuffle=True,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>define the model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class BasisNet(nn.Module):\n",
    "    def __init__(self, embedding_size=128):\n",
    "        super(BasisNet, self).__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        for param in self.inception.parameters():\n",
    "            param.requires_grad=False\n",
    "        num_ftrs = self.inception.fc.in_features\n",
    "        self.inception.fc = nn.Linear(num_ftrs, 512)\n",
    "        self.elu = nn.ELU()\n",
    "        self.final = nn.Linear(512, embedding_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.inception(x)[0]\n",
    "        x = self.elu(x)\n",
    "        x = self.final(x)\n",
    "        return self.l2_norm(x)\n",
    "    \n",
    "    def l2_norm(self,inp):\n",
    "        input_size = inp.size()\n",
    "        buffer = torch.pow(inp, 2)\n",
    "\n",
    "        normp = torch.sum(buffer, 1).add_(1e-10)\n",
    "        norm = torch.sqrt(normp)\n",
    "\n",
    "        _output = torch.div(inp, norm.view(-1, 1).expand_as(inp))\n",
    "\n",
    "        output = _output.view(input_size)\n",
    "\n",
    "        return output\n",
    "        \n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, positive, anchor, negative):\n",
    "        output1 = self.embedding_net(positive)\n",
    "        output2 = self.embedding_net(anchor)\n",
    "        output3 = self.embedding_net(negative)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "    \n",
    "    \n",
    "dress_net = TripletNet(BasisNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad,dress_net.parameters()), lr=0.001, momentum=0.9)\n",
    "criterion = TripletLoss(0.1) \n",
    "EPOCH = 2\n",
    "for i in range(EPOCH):\n",
    "    losses = []\n",
    "    for batch_i, (positive, anchor, negative) in enumerate(train_dataset_loader):\n",
    "        positive, anchor, negative = Variable(positive), Variable(anchor), Variable(negative)\n",
    "        p,a,n = dress_net(anchor, positive, negative)\n",
    "        loss = criterion(p,a,n)\n",
    "        losses.append(loss.data[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print batch_i\n",
    "    print np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
